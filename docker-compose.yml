version: '3'
services:
  # Datamart
  datamart:
    image: postgres:11
    environment:
      POSTGRES_DB: datamart
      POSTGRES_USER: datamart
      POSTGRES_PASSWORD: datamart

  # Metabase
  metabase:
    image: metabase/metabase:latest
    ports:
      - 13000:3000

  # Hive Metastore
  metastore:
    image: wdpbigdata/hive-metastore:latest
    depends_on:
      - metastore-db
      - minio
  metastore-db:
    image: postgres:11
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: metastore
      POSTGRES_PASSWORD: metastore

  # MinIO
  minio:
    image: minio/minio:latest
    command: server /data
    environment:
      - MINIO_ACCESS_KEY=accesskey
      - MINIO_SECRET_KEY=secretkey
    volumes:
      - ./data:/data
    ports:
      - 9000:9000

  # Spark
  spark-submit:
    image: wdpbigdata/spark:latest
    entrypoint: spark-submit --packages org.apache.hadoop:hadoop-aws:3.2.0
    volumes:
      - ./src/scripts:/opt/scripts

  # Presto server 
  presto-server:
    image: wdpbigdata/presto:latest
    depends_on:
      - metastore
    platform: linux/amd64
    ports:
      - "8080:8080" 

  # Presto CLI         
  presto-cli:
    image: wdpbigdata/presto:latest
    entrypoint: /opt/presto-cli --server http://presto-server:8080
    # platform: linux/amd64
    # tty: true 

  # Python
  python:
    image: wdpbigdata/python:latest
    entrypoint: python
    volumes:
      - .//Users/linpeihsuan/Documents/resume-repo/airflow-practice/src/airflow_practice
  jupyter-console:
    image: wdpbigdata/python:latest
    entrypoint: jupyter-console

  # airflow
  airflow:
    image: apache/airflow:2.6.2
    container_name: local_airflow
    depends_on:
      - datamart
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__FERNET_KEY: "hp2kJOJhExa9uDdj41oWF-w08LG9KWlg-lNE3rVjZTY="
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://datamart:datamart@datamart:5432/datamart
      AIRFLOW__WEBSERVER__SECRET_KEY: airflow_secret_key
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
      - ./data/.raw:/opt/airflow/data
    ports:
      - "8080:8080"
    command: >
      bash -c "airflow db init &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com &&
      airflow webserver & sleep 5 && airflow scheduler"